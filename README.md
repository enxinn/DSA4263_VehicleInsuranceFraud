## Table of Contents

- [Abstract](#abstract)
- [Repository Structure](#repository-structure)
- [How to Run This Project](#how-to-run-this-project)
- [Flask Web Application](#flask-web-application)
- [Docker Deployment](#docker-deployment)

## Abstract
Insurance fraud poses a major challenge to the industry, leading to significant financial losses, higher premiums and heavy manual investigation workload. To tackle this issue, our project develops a machine learning model to detect fraudulent vehicle insurance claims using a [dataset](https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection) containing 15,420 records. The dataset is highly imbalanced, with only around 6% fraudulent cases, making accurate detection difficult. 

After data cleaning, feature engineering, and exploratory data analysis, multiple resampling techniques were tested to handle imbalance, with SMOTEENN selected for providing the best minority-class detection. Several models were then trained, including Logistic Regression, Decision Tree, Random Forest, LightGBM, XGBoost and SVC. Among all models, a tuned LightGBM achieved the strongest performance, with a PR-AUC of 0.69, precision of 0.60 and recall of 0.67 on the test set, showing a good balance between identifying fraud and controlling false alarms.

Explainability method SHAP was used to explain the model’s prediction, revealing that features related to fault, policy type, deductibles, and claim timing strongly influence predictions. Fairness testing showed that the model performed unevenly across age groups, particularly for older policyholders, indicating potential bias that should be addressed before deployment.

Overall, the model demonstrates strong potential to support fraud investigators, reduce operational costs and offer insights into fraud patterns. Recommendations include targeted review strategies, better monitoring of first-time claimants, and complementing the model with tools such as graph analytics and NLP for enhanced fraud detection.

## Repository Structure
```
DSA4263_VehicleInsuranceFraud/
├── README.md 
├── data/
│   ├──  processed/                  # Cleaned / engineered datasets
│   └──  raw/                        # Original fraud_oracle.csv
├── main.ipynb/                      # Run this to run all notebooks
├── models/                          # Trained final model
├── notebooks/                       # Jupyter notebooks
├── templates/
├── Dockerfile
├── app.py
├── data_dictionary.txt
├── docker-compose.yml
├── requirements_full_pipeline.txt   # The requirements file for reproducing the entire workflow
└── requirements.txt                 # The requirements file for final machine learning model
```

## How to Run This Project
To execute the entire machine learning workflow, run [main.ipynb](https://github.com/enxinn/DSA4263_VehicleInsuranceFraud/blob/fa021e614d21f68ae5ecf9f51b3f7354a1aa79de/main.ipynb) from the project root. Before running, please install the required packages using: ```pip install -r requirements_full_pipeline.txt```. This notebook automatically runs all other notebooks in the correct order. 

Running this pipeline will perform:
- Data preprocessing, exploratory data analysis, and resampling
- Training and validation of multiple machine learning models
- Final model training, including test evaluation, explainability and fairness analysis
- Saving the final trained model into the models/ directory

## Flask Web Application
This project includes a simple Flask-based web application that allows users to manually input claim information and receive a fraud prediction generated by the trained LightGBM model.
The application serves as an interactive demonstration of the final machine learning model and enables real-time inference.

## Docker Deployment
To ensure consistent and reproducible execution across different environments, the Flask prediction application is fully containerized using Docker. This allows the app to run identically on any machine without needing to manually install Python, dependencies, or model files.

### Docker Files Included:
1. Dockerfile
- Defines the environment, installs dependencies, and runs the Flask app using Gunicorn (a production WSGI server).

2. docker-compose.yml
- Provides a simple command to build and run the application container.
  
Follow these steps to deploy the fraud detection app using Docker:
1. From the project root directory (same folder as the Dockerfile), run **docker compose build**
   - pulls the official Python 3.12 image
   - installs all dependencies listed in requirements.txt
   - copies the Flask app, templates, and model
   - prepares Gunicorn as the production server
  
2. Run the Application Container
   - run **docker compose up**
  
3. Access the Application
   - Open browser when request is prompted
   - The request is routed to the container’s internal Flask server (port 5000) using the mapping defined in docker-compose.yml
   - Key in relevant details (eg Policy Number, Age, RepNumber etc) and submit to obtain an outcome: *Fraud suspected* or *Fraud not suspected*
  
4. To fully stop and remove the container:
   - run **docker compose down**


