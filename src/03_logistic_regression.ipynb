{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea224e0-074a-47c4-8dfd-7b2509933311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a66a0e-c26c-4521-89b9-fc580e9a6359",
   "metadata": {},
   "source": [
    "### Reading in data and splitting into train, validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28309c5b-b4ac-40ed-9737-73296e1e1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d079d4af-bd36-4851-b4fe-8d2bdf64e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15420, 45)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f91aca8b-b838-48ca-90e1-ddb4b7ae0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and response\n",
    "X = df.drop(columns=['FraudFound_P'])\n",
    "y = df['FraudFound_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df3f01d2-0e99-435a-b8d8-0bffbd62d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (12336, 44) (12336,)\n",
      "Testing set shape: (3084, 44) (3084,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into training (80% of whole dataset) and testing (20% of whole dataset) \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,   # ensures reproducibility\n",
    "    stratify=y         # preserves class balance\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce10b1ef-b3c9-4f5e-bb03-2d5773349634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (9252, 44) (9252,)\n",
      "Validation set shape: (3084, 44) (3084,)\n",
      "Testing set shape: (3084, 44) (3084,)\n"
     ]
    }
   ],
   "source": [
    "# Further split training into training (60% of whole dataset) and validation (20% of whole dataset) \n",
    "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=42,   # ensures reproducibility\n",
    "    stratify=y_train         # preserves class balance\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_subtrain.shape, y_subtrain.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448838c-bb58-4ab9-b7d3-4ff0fc16eb5f",
   "metadata": {},
   "source": [
    "Above, we have effectively split the data into 60% train, 20% validation, and 20% test. The training and validation sets will be used for the train-validation set approach, while the full training set (train and validation combined) will be used to perform cross-validation later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8317f-f821-4075-9e1f-1db627d1eecc",
   "metadata": {},
   "source": [
    "### Function to check class proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "429c4f41-2351-4c90-bf08-f815019a7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_proportions(y):\n",
    "    \"\"\"\n",
    "    Prints the count and proportion of each class in a pandas Series or array.\n",
    "    \"\"\"\n",
    "    y_series = pd.Series(y, name=\"label\")\n",
    "    counts = y_series.value_counts().sort_index()\n",
    "    proportions = y_series.value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        \"count\": counts,\n",
    "        \"proportion\": proportions.round(4)\n",
    "    })\n",
    "    \n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6c3dc-1244-439f-a78b-b60b7f637bc9",
   "metadata": {},
   "source": [
    "## Logistic Regression (Base Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedbd59-4927-4d35-9ba5-f4595a4f853f",
   "metadata": {},
   "source": [
    "### Train-validation set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e693830-f599-4b22-9a7b-009a877d2a43",
   "metadata": {},
   "source": [
    "Now, we use the train-validation set approach to conduct hyperparameter tuning on the logistic regression model. The model with the combination of hyperparameters which produces the highest validation F1-score will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dc8de05-25b8-41f6-a881-d0e53b2dd7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train–Validation Hyperparameter Tuning Results ===\n",
      "Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'class_weight': 'balanced'}\n",
      "Best F1 Score (Validation): 0.2241\n",
      "\n",
      "=== Metrics for Selected Model (Optimal Hyperparameters) ===\n",
      "Accuracy  : 0.6767\n",
      "Precision : 0.1308\n",
      "Recall    : 0.7826\n",
      "F1        : 0.2241\n",
      "ROC-AUC   : 0.7831\n",
      "PR-AUC    : 0.1390\n",
      "\n",
      "=== Classification Summary for Best Model ===\n",
      "Confusion Matrix:\n",
      " [[1943  957]\n",
      " [  40  144]]\n",
      "\n",
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_67e01 th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_67e01 td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_67e01\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_67e01_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_67e01_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_67e01_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_67e01_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_67e01_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_67e01_row0_col0\" class=\"data row0 col0\" >0.979829</td>\n",
       "      <td id=\"T_67e01_row0_col1\" class=\"data row0 col1\" >0.670000</td>\n",
       "      <td id=\"T_67e01_row0_col2\" class=\"data row0 col2\" >0.795822</td>\n",
       "      <td id=\"T_67e01_row0_col3\" class=\"data row0 col3\" >2900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67e01_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_67e01_row1_col0\" class=\"data row1 col0\" >0.130790</td>\n",
       "      <td id=\"T_67e01_row1_col1\" class=\"data row1 col1\" >0.782609</td>\n",
       "      <td id=\"T_67e01_row1_col2\" class=\"data row1 col2\" >0.224125</td>\n",
       "      <td id=\"T_67e01_row1_col3\" class=\"data row1 col3\" >184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67e01_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_67e01_row2_col0\" class=\"data row2 col0\" >0.676719</td>\n",
       "      <td id=\"T_67e01_row2_col1\" class=\"data row2 col1\" >0.676719</td>\n",
       "      <td id=\"T_67e01_row2_col2\" class=\"data row2 col2\" >0.676719</td>\n",
       "      <td id=\"T_67e01_row2_col3\" class=\"data row2 col3\" >0.676719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67e01_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_67e01_row3_col0\" class=\"data row3 col0\" >0.555309</td>\n",
       "      <td id=\"T_67e01_row3_col1\" class=\"data row3 col1\" >0.726304</td>\n",
       "      <td id=\"T_67e01_row3_col2\" class=\"data row3 col2\" >0.509973</td>\n",
       "      <td id=\"T_67e01_row3_col3\" class=\"data row3 col3\" >3084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67e01_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_67e01_row4_col0\" class=\"data row4 col0\" >0.929173</td>\n",
       "      <td id=\"T_67e01_row4_col1\" class=\"data row4 col1\" >0.676719</td>\n",
       "      <td id=\"T_67e01_row4_col2\" class=\"data row4 col2\" >0.761713</td>\n",
       "      <td id=\"T_67e01_row4_col3\" class=\"data row4 col3\" >3084.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1953e4fb260>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_metrics = {}\n",
    "best_model = None\n",
    "\n",
    "# --- Hyperparameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],      # supports both L1 and L2\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# --- Loop through all combinations ---\n",
    "for C, penalty, solver, class_weight in product(\n",
    "    param_grid['C'],\n",
    "    param_grid['penalty'],\n",
    "    param_grid['solver'],\n",
    "    param_grid['class_weight']\n",
    "):\n",
    "    try:\n",
    "        model = LogisticRegression(\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            class_weight=class_weight,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_subtrain, y_subtrain)\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        prec = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_val, y_val_prob)\n",
    "\n",
    "        # --- Compute PR-AUC ---\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_val_prob)\n",
    "        pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "        # Track best model (based on F1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = {\n",
    "                'C': C,\n",
    "                'penalty': penalty,\n",
    "                'solver': solver,\n",
    "                'class_weight': class_weight\n",
    "            }\n",
    "            best_metrics = {\n",
    "                'Accuracy': acc,\n",
    "                'Precision': prec,\n",
    "                'Recall': rec,\n",
    "                'F1': f1,\n",
    "                'ROC-AUC': roc_auc,\n",
    "                'PR-AUC': pr_auc\n",
    "            }\n",
    "            best_model = model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped combination (C={C}, penalty={penalty}) due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- Summary of tuning results ---\n",
    "print(\"\\n=== Train–Validation Hyperparameter Tuning Results ===\")\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Best F1 Score (Validation): {best_f1:.4f}\\n\")\n",
    "\n",
    "print(\"=== Metrics for Selected Model (Optimal Hyperparameters) ===\")\n",
    "for metric, value in best_metrics.items():\n",
    "    print(f\"{metric:10s}: {value:.4f}\")\n",
    "\n",
    "# --- Classification summary  ---\n",
    "print(\"\\n=== Classification Summary for Best Model ===\")\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "report_dict = classification_report(y_val, y_val_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "display(report_df.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('text-align', 'center')]},\n",
    "     {'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    ").format(precision=6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3981a-9f70-4c9b-a7a7-c832db8bcb83",
   "metadata": {},
   "source": [
    "The results of the train-validation approach suggest that the model with the hyperparameter combination: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'class_weight': 'balanced'} is the optimal one which produces the highest validation F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4478f28-b5e4-402d-bab0-854adc2164a3",
   "metadata": {},
   "source": [
    "### 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a025f1a-7868-4b52-9fa6-a57ed47f2c85",
   "metadata": {},
   "source": [
    "Here, 5-fold CV is performed on the full training set to conduct hyperparameter tuning. We keep the actual test set separate, reserving it for the final model evaluation. The model with the combination of hyperparameters which yields the highest average cross-validated F1-score will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f960e1e-4ea7-4cce-b9d7-0b0eb30c1eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "=== Cross-Validation Hyperparameter Tuning Results ===\n",
      "Best Parameters: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Mean F1 (CV): 0.2211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, auc, average_precision_score   \n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Logistic Regression base model ---\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# --- Hyperparameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# --- 5-fold Stratified CV setup ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- Optimize for F1-score ---\n",
    "grid = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    error_score='raise'\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# --- Best hyperparameters ---\n",
    "best_model = grid.best_estimator_\n",
    "print(\"\\n=== Cross-Validation Hyperparameter Tuning Results ===\")\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(f\"Best Mean F1 (CV): {grid.best_score_:.4f}\")\n",
    "\n",
    "# --- Cross-validation predictions ---\n",
    "y_train_pred = cross_val_predict(best_model, X_train, y_train, cv=cv)\n",
    "y_train_prob = cross_val_predict(best_model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee673690-efe7-4dea-8075-c5ff424d341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Metrics for Selected Model (Optimal Hyperparameters) ===\n",
      "Accuracy  : 0.6612\n",
      "Precision : 0.1281\n",
      "Recall    : 0.8035\n",
      "F1        : 0.2210\n",
      "ROC-AUC   : 0.7799\n",
      "PR-AUC    : 0.1354\n",
      "Avg Precision (AP): 0.1361\n",
      "\n",
      "=== Classification Summary for Best Model ===\n",
      "Confusion Matrix:\n",
      " [[7563 4035]\n",
      " [ 145  593]]\n",
      "\n",
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2dadc th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_2dadc td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2dadc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2dadc_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_2dadc_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_2dadc_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_2dadc_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2dadc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2dadc_row0_col0\" class=\"data row0 col0\" >0.981188</td>\n",
       "      <td id=\"T_2dadc_row0_col1\" class=\"data row0 col1\" >0.652095</td>\n",
       "      <td id=\"T_2dadc_row0_col2\" class=\"data row0 col2\" >0.783487</td>\n",
       "      <td id=\"T_2dadc_row0_col3\" class=\"data row0 col3\" >11598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dadc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2dadc_row1_col0\" class=\"data row1 col0\" >0.128133</td>\n",
       "      <td id=\"T_2dadc_row1_col1\" class=\"data row1 col1\" >0.803523</td>\n",
       "      <td id=\"T_2dadc_row1_col2\" class=\"data row1 col2\" >0.221021</td>\n",
       "      <td id=\"T_2dadc_row1_col3\" class=\"data row1 col3\" >738.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dadc_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_2dadc_row2_col0\" class=\"data row2 col0\" >0.661154</td>\n",
       "      <td id=\"T_2dadc_row2_col1\" class=\"data row2 col1\" >0.661154</td>\n",
       "      <td id=\"T_2dadc_row2_col2\" class=\"data row2 col2\" >0.661154</td>\n",
       "      <td id=\"T_2dadc_row2_col3\" class=\"data row2 col3\" >0.661154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dadc_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_2dadc_row3_col0\" class=\"data row3 col0\" >0.554661</td>\n",
       "      <td id=\"T_2dadc_row3_col1\" class=\"data row3 col1\" >0.727809</td>\n",
       "      <td id=\"T_2dadc_row3_col2\" class=\"data row3 col2\" >0.502254</td>\n",
       "      <td id=\"T_2dadc_row3_col3\" class=\"data row3 col3\" >12336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dadc_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_2dadc_row4_col0\" class=\"data row4 col0\" >0.930154</td>\n",
       "      <td id=\"T_2dadc_row4_col1\" class=\"data row4 col1\" >0.661154</td>\n",
       "      <td id=\"T_2dadc_row4_col2\" class=\"data row4 col2\" >0.749838</td>\n",
       "      <td id=\"T_2dadc_row4_col3\" class=\"data row4 col3\" >12336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1953bd20470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, auc, average_precision_score   \n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --- Compute metrics using cross-validation predictions ---\n",
    "acc = accuracy_score(y_train, y_train_pred)\n",
    "prec = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "rec = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "f1 = f1_score(y_train, y_train_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_train, y_train_prob)\n",
    "\n",
    "# --- PR curve & areas ---\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_train, y_train_prob)\n",
    "pr_auc = auc(rec_curve, prec_curve)                 # area under PR curve\n",
    "avg_prec = average_precision_score(y_train, y_train_prob)  # AP (threshold-free)\n",
    "\n",
    "print(\"\\n=== Metrics for Selected Model (Optimal Hyperparameters) ===\")\n",
    "print(f\"Accuracy  : {acc:.4f}\")\n",
    "print(f\"Precision : {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")\n",
    "print(f\"F1        : {f1:.4f}\")\n",
    "print(f\"ROC-AUC   : {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC    : {pr_auc:.4f}\")\n",
    "print(f\"Avg Precision (AP): {avg_prec:.4f}\")\n",
    "\n",
    "# --- Confusion matrix and classification report ---\n",
    "print(\"\\n=== Classification Summary for Best Model ===\")\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "report_dict = classification_report(y_train, y_train_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "display(report_df.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('text-align', 'center')]},\n",
    "     {'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    ").format(precision=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018d2a9-84c7-4df4-81ba-bd6abb5f9af3",
   "metadata": {},
   "source": [
    "The 5-fold CV results suggest that the model with the hyperparameter combination: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'} is the optimal one which produces the highest average cross-validated F1-score. The optimal hyperparameter combination selected by 5-fold CV is similar to that chosen using the train-validation approach earlier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
